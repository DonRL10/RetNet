{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from model import RetNET\n",
    "from tinystories import Task\n",
    "\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iters = partial(Task.iter_batches, batch_size = 32, max_seq_len = 256, device = 'cuda', num_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        batch_iter = iters(split)\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = next(batch_iter)\n",
    "            _, loss, _ = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelConifg:\n",
    "    nembed = 288\n",
    "    nheads = 6\n",
    "    nlayers = 6\n",
    "\n",
    "    vocab_size = 32000\n",
    "    block_size = 256\n",
    "\n",
    "    device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ModelConifg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametres 22951904\n"
     ]
    }
   ],
   "source": [
    "model = RetNET(config).to('cuda')\n",
    "print(\"Parametres\", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iters = 5000\n",
    "eval_iters = 50\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = 3e-4)\n",
    "\n",
    "train_iters = iters('train')\n",
    "xb, yb = next(train_iters)\n",
    "\n",
    "from tqdm import tqdm\n",
    "pbar = tqdm(range(max_iters))\n",
    "\n",
    "micro_batches = 2\n",
    "\n",
    "for i in pbar:\n",
    "    for m in range(micro_batches):\n",
    "        _, loss, _ = model(xb, yb)\n",
    "        loss = loss / micro_batches\n",
    "        xb, yb = next(train_iters) # to prefetch batches asyncally on while model in doing its ting in gpu\n",
    "        loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad(set_to_none = True)\n",
    "    # pbar.set_description(f\"Loss {loss.item():.4f}\")\n",
    "    if i % 500== 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"\\nStep {i}: train_loss {losses['train']:.4f}  val_loss {losses['val']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"tiny_stories_28866.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizer import Tokeniser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = Tokeniser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kyle was very excited to keep everyone safe. One day they went for a drive in their car. As they drove by, they found a beautiful park. In the park was a slide, windows with a rainbow slide. They all laughed and played there too.\n",
      "As the day went on, Kat and their moms let them go in. Everyone was so happy and excited!\n",
      "Felix Celia and their mum would always be ready for all of the animals. They raced around through the park so they could see even small birds in the sky while they drove away.\n",
      "They packed up their carrots and then they returned to their destination.\n",
      "When they arrived, everyone was so excited. They were so excited. They explored the park and finally arrived in the park. It was a beautiful place in the park.\n",
      "\"Look at this expensive thing!\" Rachel said proudly.\n",
      "Welia smiled and they enjoyed the cool trash of their adventure. Billy and her mommy were playing in the park together. Billy was having so much fun, jumping around and swinging in the trees. Suddenly, Billy's mom came in and stopped their running. She said, \"Stop Go away, Billy! You don't want to tie so many to your runs\".\n",
      "Billy was sad, but he understood. He said, \"Okay, okay, okay. I will be more next time!\"\n",
      "B\n"
     ]
    }
   ],
   "source": [
    "context = \"Kyle\"\n",
    "out = model.generate(torch.tensor([enc.encode(context, True, False)], dtype = torch.long, device = 'cuda'), steps = 300)\n",
    "print(\"\".join(enc.decode(out[0].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
