{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"harry potter.txt\", 'r', encoding = \"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "stoi = {ch: i for i, ch in enumerate(chars)}\n",
    "itos = {i: ch for ch, i in stoi.items()}\n",
    "encode = lambda x: [stoi[s] for s in x]\n",
    "decode = lambda x: \"\".join([itos[i] for i in x])\n",
    "\n",
    "data = torch.tensor(encode(text), dtype = torch.long)\n",
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "batch_size = 64\n",
    "device = 'cuda'\n",
    "\n",
    "def get_batch(block_size, device, split):\n",
    "    data = train_data if split == \"train\" else val_data\n",
    "    ix = torch.randint(len(data) - block_size - 1, (batch_size, ))\n",
    "    x = torch.stack([data[i: i + block_size] for i in ix])\n",
    "    y = torch.stack([data[i + 1: i + block_size + 1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(config.block_size, device, split)\n",
    "            _, loss, _ = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelConifg:\n",
    "    nembed = 256\n",
    "    nheads = 4\n",
    "    nlayers = 4\n",
    "\n",
    "    vocab_size = 100\n",
    "    block_size = 256\n",
    "\n",
    "    device = device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import RetNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ModelConifg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametres 2415972\n"
     ]
    }
   ],
   "source": [
    "model = RetNET(config).to(device)\n",
    "print(\"Parametres\", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss 1.0869:   0%|          | 1/2000 [00:09<5:32:45,  9.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 0: train_loss 1.2440  val_loss 1.3175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss 1.0469:  25%|██▌       | 501/2000 [02:20<1:18:13,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 500: train_loss 1.0563  val_loss 1.1451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss 1.0257:  50%|█████     | 1001/2000 [04:29<50:36,  3.04s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 1000: train_loss 1.0356  val_loss 1.1419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss 0.9916:  75%|███████▌  | 1501/2000 [06:37<25:31,  3.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 1500: train_loss 1.0150  val_loss 1.1301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss 1.0080: 100%|██████████| 2000/2000 [08:34<00:00,  3.89it/s]\n"
     ]
    }
   ],
   "source": [
    "max_iters = 2000\n",
    "eval_iters = 50\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = 1e-3)\n",
    "\n",
    "from tqdm import tqdm\n",
    "pbar = tqdm(range(max_iters))\n",
    "\n",
    "for i in pbar:\n",
    "    xb, yb = get_batch(config.block_size, device, split = 'train')\n",
    "    _, loss, _ = model(xb, yb)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad(set_to_none = True)\n",
    "    pbar.set_description(f\"Loss {loss.item():.4f}\")\n",
    "    if i % 500== 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"\\nStep {i}: train_loss {losses['train']:.4f}  val_loss {losses['val']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "there, but Harry examined at the people from sir \n",
      "watch. There was a good likely to the fire. They \n",
      "stared around and his small, and the verge was accompanied \n",
      "up a carrying crowd. \n",
      "\n",
      "They brought jet that Fred and Harry and Professor \n",
      "Snape frother them, looking around, necking a run \n",
      "raporation standing on the pavement out of his hand. \n",
      "\n",
      "Their free tunneless; Dudley managed to make a shove. \n",
      "Silend of what happened to, quill it winning the \n",
      "Educire on his magical equarl group of some lurky. \n",
      "They were too only to start on the way, Harry could \n",
      "see enough to rest a jet of parchment din “Shell Finnigan \n",
      "Ligomottom fill magic ovacious Vernon at the bars. \n",
      "YOUS TVE LEASS GET MORTLES BULD-EV THE TOES \n",
      "SCUSPLES are POILIS’; the Chible of JObEDE-MOOceno on \n",
      "one. Harry Potter undoubranted deserves. We asked \n",
      "Dear Defense Against the Mud! Now? We beginned. A \n",
      "shadow on Magnoscule not the blushy and think about \n",
      "this gought and handson; it was finally on the other \n",
      "year on the table before them\n"
     ]
    }
   ],
   "source": [
    "context = \"\\n\"\n",
    "out = model.generate(torch.tensor([encode(context)], dtype = torch.long, device = device), steps = 1000)\n",
    "print(\"\".join(decode(out[0].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
